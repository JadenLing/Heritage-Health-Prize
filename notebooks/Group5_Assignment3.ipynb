{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42636\\2009690890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"Claims\": \"./HHP_release3/Claims.csv\",\n",
    "    \"DaysInHospital_Y2\": \"./HHP_release3/DaysInHospital_Y2.csv\",\n",
    "    \"DaysInHospital_Y3\": \"./HHP_release3/DaysInHospital_Y3.csv\",\n",
    "    \"DrugCount\": \"./HHP_release3/DrugCount.csv\",\n",
    "    \"LabCount\": \"./HHP_release3/LabCount.csv\",\n",
    "    \"Members\": \"./HHP_release3/Members.csv\",\n",
    "    \"Target\": \"./HHP_release3/Target.csv\"\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "claims_df = pd.read_csv(file_paths['Claims'])\n",
    "days_in_hospital_y2_df = pd.read_csv(file_paths['DaysInHospital_Y2'])\n",
    "days_in_hospital_y3_df = pd.read_csv(file_paths['DaysInHospital_Y3'])\n",
    "drug_count_df = pd.read_csv(file_paths['DrugCount'])\n",
    "lab_count_df = pd.read_csv(file_paths['LabCount'])\n",
    "members_df = pd.read_csv(file_paths['Members'])\n",
    "target_df = pd.read_csv(file_paths['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Claims:\n",
      "                       Missing Values  Percentage\n",
      "ProviderID                      16264    0.609369\n",
      "Vendor                          24856    0.931289\n",
      "PCP                              7492    0.280705\n",
      "Specialty                        8405    0.314913\n",
      "PlaceSvc                         7632    0.285951\n",
      "LengthOfStay                  2597392   97.317412\n",
      "DSFS                            52770    1.977152\n",
      "PrimaryConditionGroup           11410    0.427503\n",
      "ProcedureGroup                   3675    0.137693\n",
      "\n",
      "\n",
      "Missing values in DaysInHospital_Y2:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Missing values in DaysInHospital_Y3:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Missing values in DrugCount:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Missing values in LabCount:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Missing values in Members:\n",
      "                 Missing Values  Percentage\n",
      "AgeAtFirstClaim            5753    5.091150\n",
      "Sex                       17552   15.532743\n",
      "\n",
      "\n",
      "Missing values in Target:\n",
      "                Missing Values  Percentage\n",
      "DaysInHospital           70942       100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def missing_data_summary(df, dataset_name):\n",
    "    print(f\"Missing values in {dataset_name}:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percentage = (missing_data / len(df)) * 100\n",
    "    missing_summary = pd.DataFrame({'Missing Values': missing_data, 'Percentage': missing_percentage})\n",
    "    print(missing_summary[missing_summary['Missing Values'] > 0])  # Only show columns with missing values\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Get missing data summary for each dataset\n",
    "missing_data_summary(claims_df, \"Claims\")\n",
    "missing_data_summary(days_in_hospital_y2_df, \"DaysInHospital_Y2\")\n",
    "missing_data_summary(days_in_hospital_y3_df, \"DaysInHospital_Y3\")\n",
    "missing_data_summary(drug_count_df, \"DrugCount\")\n",
    "missing_data_summary(lab_count_df, \"LabCount\")\n",
    "missing_data_summary(members_df, \"Members\")\n",
    "missing_data_summary(target_df, \"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['DSFS'].fillna(claims_df['DSFS'].median(), inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['ProviderID'].fillna(claims_df['ProviderID'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['Vendor'].fillna(claims_df['Vendor'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['PCP'].fillna(claims_df['PCP'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['Specialty'].fillna(claims_df['Specialty'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['PlaceSvc'].fillna(claims_df['PlaceSvc'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['PrimaryConditionGroup'].fillna(claims_df['PrimaryConditionGroup'].mode()[0], inplace=True)\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_37936\\1600725830.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  claims_df['ProcedureGroup'].fillna(claims_df['ProcedureGroup'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define mapping for 'DSFS' conversion to numeric\n",
    "dsfs_mapping = {\n",
    "    '0- 1 month': 1,\n",
    "    '1- 2 months': 2,\n",
    "    '2- 3 months': 3,\n",
    "    '3- 4 months': 4,\n",
    "    '4- 5 months': 5,\n",
    "    '5- 6 months': 6,\n",
    "    '6- 7 months': 7,\n",
    "    '7- 8 months': 8,\n",
    "    '8- 9 months': 9,\n",
    "    '9-10 months': 10,\n",
    "    '10-11 months': 11,\n",
    "    '11-12 months': 12\n",
    "}\n",
    "\n",
    "# Apply the mapping to the DSFS column to convert it to numeric\n",
    "claims_df['DSFS'] = claims_df['DSFS'].map(dsfs_mapping)\n",
    "\n",
    "# Fill the missing DSFS values using the median\n",
    "claims_df['DSFS'].fillna(claims_df['DSFS'].median(), inplace=True)\n",
    "\n",
    "# Imputation for other columns (unchanged)\n",
    "claims_df['ProviderID'].fillna(claims_df['ProviderID'].mode()[0], inplace=True)\n",
    "claims_df['Vendor'].fillna(claims_df['Vendor'].mode()[0], inplace=True)\n",
    "claims_df['PCP'].fillna(claims_df['PCP'].mode()[0], inplace=True)\n",
    "claims_df['Specialty'].fillna(claims_df['Specialty'].mode()[0], inplace=True)\n",
    "claims_df['PlaceSvc'].fillna(claims_df['PlaceSvc'].mode()[0], inplace=True)\n",
    "claims_df['PrimaryConditionGroup'].fillna(claims_df['PrimaryConditionGroup'].mode()[0], inplace=True)\n",
    "claims_df['ProcedureGroup'].fillna(claims_df['ProcedureGroup'].mode()[0], inplace=True)\n",
    "\n",
    "# Dropping 'LengthOfStay' due to high missing values\n",
    "claims_df.drop(columns=['LengthOfStay'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (58297637, 24)\n"
     ]
    }
   ],
   "source": [
    "# Merge Claims and Members datasets on 'MemberID'\n",
    "merged_df = pd.merge(claims_df, members_df, on='MemberID', how='left')\n",
    "\n",
    "# Merge DaysInHospital_Y2 and DaysInHospital_Y3\n",
    "merged_df = pd.merge(merged_df, days_in_hospital_y2_df, on='MemberID', how='left')\n",
    "merged_df = pd.merge(merged_df, days_in_hospital_y3_df, on='MemberID', how='left')\n",
    "\n",
    "# Merge DrugCount and LabCount on 'MemberID' and 'Year'\n",
    "merged_df = pd.merge(merged_df, drug_count_df, on=['MemberID', 'Year'], how='left')\n",
    "merged_df = pd.merge(merged_df, lab_count_df, on=['MemberID', 'Year'], how='left')\n",
    "\n",
    "# Merge the Target dataset\n",
    "merged_df = pd.merge(merged_df, target_df[['MemberID', 'DaysInHospital']], on='MemberID', how='left')\n",
    "\n",
    "# Check the final merged dataframe\n",
    "print(\"Merged dataset shape:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MemberID  ProviderID    Vendor      PCP Year Specialty PlaceSvc PayDelay  \\\n",
      "0  42286978   8013252.0  172193.0  37796.0   Y1   Surgery   Office       28   \n",
      "1  42286978   8013252.0  172193.0  37796.0   Y1   Surgery   Office       28   \n",
      "2  42286978   8013252.0  172193.0  37796.0   Y1   Surgery   Office       28   \n",
      "3  42286978   8013252.0  172193.0  37796.0   Y1   Surgery   Office       28   \n",
      "4  42286978   8013252.0  172193.0  37796.0   Y1   Surgery   Office       28   \n",
      "\n",
      "   DSFS_x PrimaryConditionGroup  ... Sex ClaimsTruncated_x  DaysInHospital_x  \\\n",
      "0     9.0               NEUMENT  ...   F               0.0               2.0   \n",
      "1     9.0               NEUMENT  ...   F               0.0               2.0   \n",
      "2     9.0               NEUMENT  ...   F               0.0               2.0   \n",
      "3     9.0               NEUMENT  ...   F               0.0               2.0   \n",
      "4     9.0               NEUMENT  ...   F               0.0               2.0   \n",
      "\n",
      "  ClaimsTruncated_y DaysInHospital_y        DSFS_y  DrugCount         DSFS  \\\n",
      "0               NaN              NaN   8- 9 months          3  9-10 months   \n",
      "1               NaN              NaN   4- 5 months          5  9-10 months   \n",
      "2               NaN              NaN   5- 6 months          2  9-10 months   \n",
      "3               NaN              NaN  11-12 months          1  9-10 months   \n",
      "4               NaN              NaN   1- 2 months          2  9-10 months   \n",
      "\n",
      "   LabCount DaysInHospital  \n",
      "0         8            NaN  \n",
      "1         8            NaN  \n",
      "2         8            NaN  \n",
      "3         8            NaN  \n",
      "4         8            NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MemberID', 'ProviderID', 'Vendor', 'PCP', 'Year', 'Specialty',\n",
      "       'PlaceSvc', 'PayDelay', 'DSFS_x', 'PrimaryConditionGroup',\n",
      "       'CharlsonIndex', 'ProcedureGroup', 'SupLOS', 'AgeAtFirstClaim', 'Sex',\n",
      "       'ClaimsTruncated_x', 'DaysInHospital_x', 'ClaimsTruncated_y',\n",
      "       'DaysInHospital_y', 'DSFS_y', 'DrugCount', 'DSFS', 'LabCount',\n",
      "       'DaysInHospital'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features into different groups\n",
    "demographic_features = ['AgeAtFirstClaim', 'Sex']\n",
    "medical_history_features = ['CharlsonIndex', 'PrimaryConditionGroup', 'ProcedureGroup']\n",
    "treatment_features = ['DrugCount', 'LabCount']\n",
    "\n",
    "# Combine all features\n",
    "features = demographic_features + medical_history_features + treatment_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'DaysInHospital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
